{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Creating interpretation dictionary...\n",
      "Generating cluster profiles...\n",
      "Saving cluster profiles...\n",
      "\n",
      "States in Each Cluster:\n",
      "Cluster 0.0:\n",
      "Alabama, Arkansas, Colorado, Connecticut, Delaware, Illinois, Kansas, Maryland, Missouri, Montana, New Hampshire, New Mexico, New York, Pennsylvania, South Carolina, Tennessee, Utah, Virginia, Washington\n",
      "--------------------------------------------------\n",
      "Cluster 1.0:\n",
      "Arizona, Florida, Georgia, Idaho, Indiana, Maine, Minnesota, Nevada, Oregon, Texas, Vermont, Wisconsin\n",
      "--------------------------------------------------\n",
      "Cluster 2.0:\n",
      "Alaska, Iowa, Kentucky, Mississippi, North Carolina, Oklahoma, West Virginia, Wyoming\n",
      "--------------------------------------------------\n",
      "Cluster 3.0:\n",
      "District of Columbia, Massachusetts, Michigan, Nebraska, Rhode Island, South Dakota\n",
      "--------------------------------------------------\n",
      "Cluster profiling completed successfully using manually updated interpretations!\n"
     ]
    }
   ],
   "source": [
    "# Notebook: Profile Weighted Clusters Using Manually Updated Interpretation Guide\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Load Datasets ---\n",
    "print(\"Loading datasets...\")\n",
    "clustering_results_path = 'data/kmeans_cosine_clustering_results_4_1-1_threshold_0.25_n4.csv'\n",
    "interpretation_guide_path = 'data/New_Manually_Updated_Correlation_Interpretation_Guide.csv'\n",
    "clustering_input_path = 'data/clustering_input_final_0.25.csv'\n",
    "\n",
    "df_clusters = pd.read_csv(clustering_results_path)\n",
    "df_interpretation_guide = pd.read_csv(interpretation_guide_path)\n",
    "df_clustering = pd.read_csv(clustering_input_path)\n",
    "\n",
    "# --- Step 2: Create Interpretation Dictionary ---\n",
    "print(\"Creating interpretation dictionary...\")\n",
    "interpretation_dict = {}\n",
    "for _, row in df_interpretation_guide.iterrows():\n",
    "    key = tuple(sorted([row['Metric 1'], row['Metric 2']]))  # Ensure symmetry\n",
    "    interpretation_dict[key] = {\n",
    "        \"Positive\": row['Positive Correlation Interpretation'],\n",
    "        \"Negative\": row['Negative Correlation Interpretation']\n",
    "    }\n",
    "\n",
    "# --- Step 3: Generate Cluster Profiles ---\n",
    "print(\"Generating cluster profiles...\")\n",
    "cluster_profiles = {}\n",
    "for cluster in df_clusters['Cluster'].unique():\n",
    "    cluster_df = df_clusters[df_clusters['Cluster'] == cluster]\n",
    "    states_in_cluster = cluster_df['State'].tolist()\n",
    "    cluster_data = df_clustering[df_clustering['State'].isin(states_in_cluster)]\n",
    "    \n",
    "    report = []\n",
    "    for _, row in cluster_data.iterrows():\n",
    "        key = tuple(sorted([row['Metric 1'], row['Metric 2']]))\n",
    "        correlation = row['Correlation']\n",
    "        \n",
    "        if key in interpretation_dict:\n",
    "            interpretation = interpretation_dict[key][\"Positive\"] if correlation > 0 else interpretation_dict[key][\"Negative\"]\n",
    "            report.append(f\"- {row['Metric 1']} & {row['Metric 2']}: {interpretation} (Corr: {correlation:.2f})\")\n",
    "    \n",
    "    cluster_profiles[cluster] = \"\\n\".join(report)\n",
    "\n",
    "# --- Step 4: Save Cluster Profiles as a CSV ---\n",
    "print(\"Saving cluster profiles...\")\n",
    "df_cluster_profiles = pd.DataFrame(cluster_profiles.items(), columns=['Cluster', 'Profile'])\n",
    "df_cluster_profiles.to_csv(\"data/cluster_profiles_weighted_updated_0.25_n4.csv\", index=False)\n",
    "\n",
    "# --- Step 5: Print States in Each Cluster ---\n",
    "print(\"\\nStates in Each Cluster:\")\n",
    "clustered_states = df_clusters.groupby(\"Cluster\")[\"State\"].apply(list)\n",
    "for cluster, states in clustered_states.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(\", \".join(states))  # Print states as a comma-separated list\n",
    "    print(\"-\" * 50)  # Separator for readability\n",
    "\n",
    "print(\"Cluster profiling completed successfully using manually updated interpretations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifying states missing from the clustering process...\n",
      "States missing from clustering results:\n",
      "California, Hawaii, Louisiana, New Jersey, North Dakota, Ohio\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Identify Missing States ---\n",
    "print(\"\\nIdentifying states missing from the clustering process...\")\n",
    "\n",
    "# Load the original dataset (before filtering)\n",
    "original_dataset_path = 'data/Multiple_Cause_of_Death,_1999-2014_v1.1.csv'  # Replace with actual path\n",
    "df_original = pd.read_csv(original_dataset_path)\n",
    "\n",
    "# Extract state lists\n",
    "original_states = set(df_original[\"State\"].unique())  # All states in the original dataset\n",
    "clustered_states = set(df_clusters[\"State\"].unique())  # States that were clustered\n",
    "\n",
    "# Find missing states\n",
    "missing_states = original_states - clustered_states\n",
    "\n",
    "# Print missing states if any\n",
    "if missing_states:\n",
    "    print(\"States missing from clustering results:\")\n",
    "    print(\", \".join(sorted(missing_states)))  # Print in alphabetical order for readability\n",
    "else:\n",
    "    print(\"No states were lost during clustering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
