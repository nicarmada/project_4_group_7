{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned dataset...\n",
      "Computing correlation trends for each state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicar\\AppData\\Local\\Temp\\ipykernel_3356\\3589182503.py:20: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_sorted[f\"{col} Change (%)\"] = df_sorted.groupby(\"State\")[col].pct_change() * 100\n",
      "C:\\Users\\nicar\\AppData\\Local\\Temp\\ipykernel_3356\\3589182503.py:20: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_sorted[f\"{col} Change (%)\"] = df_sorted.groupby(\"State\")[col].pct_change() * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered notable state correlation trends dataset generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Notebook: Generate Notable State Correlation Trends\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Load Cleaned Dataset ---\n",
    "print(\"Loading cleaned dataset...\")\n",
    "data_path = \"data/cleaned_multiple_cause_of_death.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert necessary columns to numeric\n",
    "numeric_columns = [\"Deaths\", \"Population\", \"Crude Rate\", \n",
    "                   \"Prescriptions Dispensed by US Retailers in that year (millions)\"]\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Sort by state and year\n",
    "df_sorted = df.sort_values(by=[\"State\", \"Year\"]).copy()\n",
    "\n",
    "# Compute Year-over-Year percentage changes for each metric\n",
    "for col in numeric_columns:\n",
    "    df_sorted[f\"{col} Change (%)\"] = df_sorted.groupby(\"State\")[col].pct_change() * 100\n",
    "\n",
    "# Drop first year for each state\n",
    "df_change = df_sorted.dropna()\n",
    "\n",
    "# --- Step 2: Compute Correlation Trends ---\n",
    "print(\"Computing correlation trends for each state...\")\n",
    "correlation_results = []\n",
    "states = df_change[\"State\"].unique()\n",
    "metrics = [col for col in df_change.columns if \"Change (%)\" in col]\n",
    "\n",
    "# Define the valid metric pairs to keep (both orientations allowed)\n",
    "valid_metric_pairs = {\n",
    "    (\"Population Change (%)\", \"Deaths Change (%)\"),\n",
    "    (\"Prescriptions Dispensed by US Retailers in that year (millions) Change (%)\", \"Deaths Change (%)\"),\n",
    "    (\"Population Change (%)\", \"Prescriptions Dispensed by US Retailers in that year (millions) Change (%)\"),\n",
    "    (\"Population Change (%)\", \"Crude Rate Change (%)\"),\n",
    "    (\"Prescriptions Dispensed by US Retailers in that year (millions) Change (%)\", \"Crude Rate Change (%)\")\n",
    "}\n",
    "\n",
    "for state in states:\n",
    "    state_df = df_change[df_change[\"State\"] == state].drop(columns=[\"State\", \"Year\"])\n",
    "    state_corr = state_df.corr().stack().reset_index()\n",
    "    state_corr.columns = [\"Metric 1\", \"Metric 2\", \"Correlation\"]\n",
    "    state_corr[\"State\"] = state\n",
    "\n",
    "    # Ensure only valid metric pairs are included, accounting for both orientations\n",
    "    state_corr = state_corr[state_corr.apply(lambda row: \n",
    "        (row[\"Metric 1\"], row[\"Metric 2\"]) in valid_metric_pairs or \n",
    "        (row[\"Metric 2\"], row[\"Metric 1\"]) in valid_metric_pairs, axis=1)]\n",
    "    \n",
    "    correlation_results.append(state_corr)\n",
    "\n",
    "# Combine all state correlation results\n",
    "df_notable_corr = pd.concat(correlation_results, ignore_index=True)\n",
    "\n",
    "# Save filtered correlation trends dataset\n",
    "df_notable_corr.to_csv(\"data/notable_state_correlation_trends_filtered.csv\", index=False)\n",
    "\n",
    "print(\"Filtered notable state correlation trends dataset generated successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing states during processing...\n",
      "No states were lost after computing percentage changes.\n",
      "States missing after correlation filtering:\n",
      "North Dakota\n",
      "\n",
      "Processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Identify Missing States at Each Stage ---\n",
    "print(\"\\nChecking for missing states during processing...\")\n",
    "\n",
    "# Load original cleaned dataset\n",
    "df_cleaned = pd.read_csv(\"data/cleaned_multiple_cause_of_death.csv\")\n",
    "original_states = set(df_cleaned[\"State\"].unique())\n",
    "\n",
    "# Extract states from dataset after computing percentage changes\n",
    "df_change_states = set(df_change[\"State\"].unique())\n",
    "\n",
    "# Extract states from final correlation results\n",
    "df_notable_corr_states = set(df_notable_corr[\"State\"].unique())\n",
    "\n",
    "# Identify missing states at each stage\n",
    "missing_after_change = original_states - df_change_states\n",
    "missing_after_correlation = df_change_states - df_notable_corr_states\n",
    "\n",
    "# Print results\n",
    "if missing_after_change:\n",
    "    print(\"States missing after computing percentage changes:\")\n",
    "    print(\", \".join(sorted(missing_after_change)))\n",
    "else:\n",
    "    print(\"No states were lost after computing percentage changes.\")\n",
    "\n",
    "if missing_after_correlation:\n",
    "    print(\"States missing after correlation filtering:\")\n",
    "    print(\", \".join(sorted(missing_after_correlation)))\n",
    "else:\n",
    "    print(\"No states were lost after correlation filtering.\")\n",
    "\n",
    "print(\"\\nProcessing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
